"""
í†µí•© ê³¼ëª© ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹œìŠ¤í…œ
24-25ë…„ë„ 4ê°œ í•™ê¸° ê°œì„¤ê°•ì¢Œ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ê³ ì„±ëŠ¥ OCR ë§¤ì¹­ DB ìƒì„±
"""

import pandas as pd
import os
import re
from glob import glob
from typing import Dict, List, Tuple
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class DatabaseBuilder:
    """í†µí•© ê³¼ëª© ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ê¸°"""

    def __init__(self, data_dir: str = "data/semester_courses"):
        self.data_dir = data_dir
        self.integrated_db = None
        self.alias_patterns = {}
        self.professor_mapping = {}

    def load_all_semesters(self) -> Dict[str, pd.DataFrame]:
        """ëª¨ë“  í•™ê¸° Excel íŒŒì¼ ë¡œë“œ"""
        excel_files = glob(os.path.join(self.data_dir, "*.xlsx"))
        logger.info(f"ë°œê²¬ëœ Excel íŒŒì¼: {len(excel_files)}ê°œ")

        semester_data = {}

        for file_path in excel_files:
            # íŒŒì¼ëª…ì—ì„œ í•™ê¸° ì •ë³´ ì¶”ì¶œ
            filename = os.path.basename(file_path)
            semester_match = re.search(r'(\d{4})-(\d{2})í•™ê¸°', filename)

            if semester_match:
                year, semester = semester_match.groups()
                semester_key = f"{year}-{semester}"

                try:
                    df = pd.read_excel(file_path)
                    df = self._standardize_columns(df)
                    semester_data[semester_key] = df
                    logger.info(f"{semester_key} í•™ê¸° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ê³¼ëª©")
                except Exception as e:
                    logger.error(f"{file_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
            else:
                logger.warning(f"í•™ê¸° ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” íŒŒì¼: {filename}")

        return semester_data

    def _standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì»¬ëŸ¼ëª… í‘œì¤€í™”"""
        # ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… íŒ¨í„´ì„ í‘œì¤€í™”
        column_mapping = {
            'êµê³¼ëª©ë²ˆí˜¸': 'ê³¼ëª©ì½”ë“œ',
            'ê³¼ëª©ë²ˆí˜¸': 'ê³¼ëª©ì½”ë“œ',
            'êµê³¼ëª©ëª…': 'ê³¼ëª©ëª…',
            'ê³¼ëª©ëª…': 'ê³¼ëª©ëª…',
            'ë‹´ë‹¹êµìˆ˜': 'êµìˆ˜ëª…',
            'êµìˆ˜ëª…': 'êµìˆ˜ëª…',
            'êµìˆ˜': 'êµìˆ˜ëª…',
            'í•™ì ': 'í•™ì ',
            'ìš”ì¼ë°ê°•ì˜ì‹œê°„': 'ì‹œê°„í‘œ',
            'ì‹œê°„í‘œ': 'ì‹œê°„í‘œ',
            'ê°•ì˜ì‹œê°„': 'ì‹œê°„í‘œ',
            'ê°•ì˜ì‹¤': 'ê°•ì˜ì‹¤',
            'êµì‹¤': 'ê°•ì˜ì‹¤',
            'ì´ìˆ˜êµ¬ë¶„': 'ì´ìˆ˜êµ¬ë¶„',
            'êµ¬ë¶„': 'ì´ìˆ˜êµ¬ë¶„'
        }

        # ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸ í›„ ë§¤í•‘
        for old_col, new_col in column_mapping.items():
            if old_col in df.columns:
                df = df.rename(columns={old_col: new_col})

        # í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ì»¬ëŸ¼ ìƒì„±
        required_columns = ['ê³¼ëª©ì½”ë“œ', 'ê³¼ëª©ëª…', 'êµìˆ˜ëª…', 'í•™ì ', 'ì‹œê°„í‘œ', 'ê°•ì˜ì‹¤']
        for col in required_columns:
            if col not in df.columns:
                df[col] = ''

        return df

    def build_integrated_database(self) -> pd.DataFrame:
        """í†µí•© ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•"""
        semester_data = self.load_all_semesters()

        if not semester_data:
            logger.error("ë¡œë“œëœ í•™ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()

        # ëª¨ë“  í•™ê¸° ë°ì´í„° ë³‘í•©
        all_courses = []

        for semester, df in semester_data.items():
            df_copy = df.copy()
            df_copy['í•™ê¸°'] = semester
            df_copy['ë“±ë¡ì¼ì‹œ'] = datetime.now()
            all_courses.append(df_copy)

        combined_df = pd.concat(all_courses, ignore_index=True)
        logger.info(f"ì „ì²´ í†µí•© ë°ì´í„°: {len(combined_df)}ê°œ ë ˆì½”ë“œ")

        # ì¤‘ë³µ ì œê±° ë° ì •ê·œí™”
        self.integrated_db = self._normalize_database(combined_df)

        # ë³„ëª…/ì•½ì¹­ ìë™ ìƒì„±
        self.integrated_db['ë³„ëª…/ì•½ì¹­'] = self.integrated_db['ê³¼ëª©ëª…'].apply(self.generate_subject_aliases)

        # êµìˆ˜-ê³¼ëª© ë§¤í•‘ êµ¬ì¶•
        self._build_professor_mapping()

        # í†µí•© DB ì €ì¥
        output_path = "data/integrated_subject_database.xlsx"
        self.integrated_db.to_excel(output_path, index=False)
        logger.info(f"í†µí•© ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {output_path}")

        return self.integrated_db

    def _normalize_database(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° ì •ê·œí™” ë° ì¤‘ë³µ ì œê±°"""

        # 1. ë°ì´í„° ì •ì œ
        df['ê³¼ëª©ì½”ë“œ'] = df['ê³¼ëª©ì½”ë“œ'].astype(str).str.strip()
        df['ê³¼ëª©ëª…'] = df['ê³¼ëª©ëª…'].astype(str).str.strip()
        df['êµìˆ˜ëª…'] = df['êµìˆ˜ëª…'].astype(str).str.strip()

        # 2. ê³¼ëª©ì½”ë“œ ê¸°ì¤€ ì¤‘ë³µ ì œê±° (ìµœì‹  í•™ê¸° ìš°ì„ )
        df = df.sort_values(['í•™ê¸°'], ascending=False)
        df_unique = df.drop_duplicates(subset=['ê³¼ëª©ì½”ë“œ'], keep='first')

        # 3. ê³¼ëª©ëª… ê¸°ì¤€ ìœ ì‚¬ ê³¼ëª© í†µí•©
        df_unique = self._merge_similar_subjects(df_unique)

        logger.info(f"ì •ê·œí™” í›„ ë°ì´í„°: {len(df_unique)}ê°œ ê³¼ëª©")
        return df_unique

    def _merge_similar_subjects(self, df: pd.DataFrame) -> pd.DataFrame:
        """ìœ ì‚¬í•œ ê³¼ëª©ëª… í†µí•©"""
        # ê³¼ëª©ëª… ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        df['ì •ê·œí™”_ê³¼ëª©ëª…'] = df['ê³¼ëª©ëª…'].str.replace(r'[\s\-\(\)]', '', regex=True)

        # ì •ê·œí™”ëœ ê³¼ëª©ëª… ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        df = df.drop_duplicates(subset=['ì •ê·œí™”_ê³¼ëª©ëª…'], keep='first')
        df = df.drop(columns=['ì •ê·œí™”_ê³¼ëª©ëª…'])

        return df

    def generate_subject_aliases(self, subject_name: str) -> str:
        """ê³¼ëª©ëª…ì—ì„œ ìë™ìœ¼ë¡œ ë³„ëª…/ì•½ì¹­ ìƒì„±"""
        if pd.isna(subject_name) or not subject_name.strip():
            return ""

        aliases = []

        # 1. ì¼ë°˜ì ì¸ ì•½ì¹­ íŒ¨í„´
        patterns = {
            'í”„ë¡œê·¸ë˜ë°': ['í”„ë¡œê·¸ë˜ë°', 'í”„ë°', 'í”„ë¡œê·¸ë˜ë°'],
            'ì»´í“¨í„°': ['ì»´í“¨í„°', 'ì»´'],
            'ë°ì´í„°ë² ì´ìŠ¤': ['ë°ì´í„°ë² ì´ìŠ¤', 'DB', 'ë°ë² ', 'ë””ë¹„'],
            'ìš´ì˜ì²´ì œ': ['ìš´ì˜ì²´ì œ', 'OS', 'ìš´ì²´'],
            'ë„¤íŠ¸ì›Œí¬': ['ë„¤íŠ¸ì›Œí¬', 'ë„¤íŠ¸', 'ë„·ì›Œí¬'],
            'ì•Œê³ ë¦¬ì¦˜': ['ì•Œê³ ë¦¬ì¦˜', 'ì•Œê³ '],
            'ì¸ê³µì§€ëŠ¥': ['ì¸ê³µì§€ëŠ¥', 'AI', 'ì¸ì§€'],
            'ì†Œí”„íŠ¸ì›¨ì–´': ['ì†Œí”„íŠ¸ì›¨ì–´', 'SW', 'ì†Œì›¨'],
            'ì‹œìŠ¤í…œ': ['ì‹œìŠ¤í…œ', 'ì‹œìŠ¤'],
            'êµ¬ì¡°': ['êµ¬ì¡°', 'êµ¬'],
            'ì„¤ê³„': ['ì„¤ê³„', 'ì„¤'],
            'ë¶„ì„': ['ë¶„ì„', 'ë¶„'],
            'ê°œë¡ ': ['ê°œë¡ ', 'ê°œ'],
            'ê³µí•™': ['ê³µí•™', 'ê³µ'],
            'ìˆ˜í•™': ['ìˆ˜í•™', 'ìˆ˜'],
            'ë¬¼ë¦¬': ['ë¬¼ë¦¬', 'ë¬¼'],
            'í™”í•™': ['í™”í•™', 'í™”'],
            'ì˜ì–´': ['ì˜ì–´', 'ì˜'],
            'í•œêµ­ì–´': ['í•œêµ­ì–´', 'í•œ'],
            'ì¤‘êµ­ì–´': ['ì¤‘êµ­ì–´', 'ì¤‘'],
            'ì¼ë³¸ì–´': ['ì¼ë³¸ì–´', 'ì¼'],
        }

        for key, values in patterns.items():
            if key in subject_name:
                aliases.extend(values)

        # 2. ì²« ê¸€ì ì•½ì–´ ìƒì„± (ì˜ˆ: ì»´í“¨í„°êµ¬ì¡° â†’ ì»´êµ¬)
        words = subject_name.replace(' ', '').replace('-', '')
        if len(words) >= 4:
            # 2ê¸€ìì”© ë¬¶ì–´ì„œ ì•½ì–´ ìƒì„±
            abbreviation = words[0] + words[len(words)//2]
            aliases.append(abbreviation)

            # ì²«ê¸€ìì™€ ë§ˆì§€ë§‰ê¸€ì
            if len(words) >= 3:
                aliases.append(words[0] + words[-1])

        # 3. ìˆ«ìê°€ í¬í•¨ëœ ê²½ìš°
        if re.search(r'\d', subject_name):
            # ìˆ«ì ì œê±° ë²„ì „
            no_digit_version = re.sub(r'\d', '', subject_name).strip()
            if no_digit_version:
                aliases.append(no_digit_version)

        # 4. ì˜ì–´ ë‹¨ì–´ í¬í•¨ëœ ê²½ìš°
        english_words = re.findall(r'[A-Za-z]+', subject_name)
        for word in english_words:
            if len(word) >= 2:
                aliases.append(word.upper())

        # ì¤‘ë³µ ì œê±° ë° ì›ë³¸ ê³¼ëª©ëª… ì œì™¸
        aliases = list(set(aliases))
        if subject_name in aliases:
            aliases.remove(subject_name)

        return ','.join(aliases)

    def _build_professor_mapping(self):
        """êµìˆ˜-ê³¼ëª© ë§¤í•‘ êµ¬ì¶•"""
        if self.integrated_db is None:
            return

        for _, row in self.integrated_db.iterrows():
            prof_name = str(row.get('êµìˆ˜ëª…', '')).strip()
            subject_name = str(row.get('ê³¼ëª©ëª…', '')).strip()

            if prof_name and prof_name != 'nan' and subject_name:
                if prof_name not in self.professor_mapping:
                    self.professor_mapping[prof_name] = []

                if subject_name not in self.professor_mapping[prof_name]:
                    self.professor_mapping[prof_name].append(subject_name)

        logger.info(f"êµìˆ˜-ê³¼ëª© ë§¤í•‘ êµ¬ì¶• ì™„ë£Œ: {len(self.professor_mapping)}ëª… êµìˆ˜")

    def get_subject_variations(self, subject_name: str) -> List[str]:
        """íŠ¹ì • ê³¼ëª©ì˜ ëª¨ë“  ë³€í˜• ê°€ì ¸ì˜¤ê¸°"""
        if self.integrated_db is None:
            return [subject_name]

        variations = [subject_name]

        # DBì—ì„œ ìœ ì‚¬í•œ ê³¼ëª©ëª… ì°¾ê¸°
        similar_subjects = self.integrated_db[
            self.integrated_db['ê³¼ëª©ëª…'].str.contains(subject_name, na=False)
        ]['ê³¼ëª©ëª…'].tolist()

        variations.extend(similar_subjects)

        # ë³„ëª…/ì•½ì¹­ì—ì„œ ì°¾ê¸°
        for _, row in self.integrated_db.iterrows():
            aliases = str(row.get('ë³„ëª…/ì•½ì¹­', ''))
            if subject_name in aliases:
                variations.append(row['ê³¼ëª©ëª…'])
                variations.extend(aliases.split(','))

        return list(set(variations))

    def get_professor_subjects(self, professor_name: str) -> List[str]:
        """íŠ¹ì • êµìˆ˜ì˜ ë‹´ë‹¹ ê³¼ëª© ëª©ë¡"""
        return self.professor_mapping.get(professor_name, [])

    def save_training_templates(self):
        """í•™ìŠµìš© í…œí”Œë¦¿ íŒŒì¼ ìƒì„±"""
        if self.integrated_db is None:
            logger.error("í†µí•© DBê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return

        # 1. ê³¼ëª©ëª… ë³„ëª… í…œí”Œë¦¿
        alias_template = self.integrated_db[['ê³¼ëª©ëª…', 'ë³„ëª…/ì•½ì¹­']].copy()
        alias_template.to_excel('data/templates/subject_aliases_template.xlsx', index=False)

        # 2. êµìˆ˜-ê³¼ëª© ë§¤í•‘ í…œí”Œë¦¿
        prof_mapping_data = []
        for prof, subjects in self.professor_mapping.items():
            for subject in subjects:
                prof_mapping_data.append({'êµìˆ˜ëª…': prof, 'ê³¼ëª©ëª…': subject})

        prof_df = pd.DataFrame(prof_mapping_data)
        prof_df.to_excel('data/templates/professor_subject_mapping.xlsx', index=False)

        # 3. ê³¼ëª© í†µê³„ í…œí”Œë¦¿
        stats_data = {
            'ì´_ê³¼ëª©ìˆ˜': len(self.integrated_db),
            'ì´_êµìˆ˜ìˆ˜': len(self.professor_mapping),
            'í‰ê· _ë³„ëª…ìˆ˜': self.integrated_db['ë³„ëª…/ì•½ì¹­'].str.split(',').str.len().mean(),
            'ìƒì„±ì¼ì‹œ': datetime.now().isoformat()
        }

        stats_df = pd.DataFrame([stats_data])
        stats_df.to_excel('data/templates/database_statistics.xlsx', index=False)

        logger.info("í•™ìŠµ í…œí”Œë¦¿ íŒŒì¼ ìƒì„± ì™„ë£Œ")

    def get_database_info(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ë°˜í™˜"""
        if self.integrated_db is None:
            return {}

        return {
            'total_subjects': len(self.integrated_db),
            'total_professors': len(self.professor_mapping),
            'unique_codes': self.integrated_db['ê³¼ëª©ì½”ë“œ'].nunique(),
            'semesters': sorted(self.integrated_db['í•™ê¸°'].unique()),
            'most_common_subjects': self.integrated_db['ê³¼ëª©ëª…'].value_counts().head(10).to_dict()
        }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“š í†µí•© ê³¼ëª© ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹œì‘")
    print("=" * 60)

    # ë°ì´í„°ë² ì´ìŠ¤ ë¹Œë” ìƒì„±
    db_builder = DatabaseBuilder()

    # í†µí•© ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
    integrated_db = db_builder.build_integrated_database()

    if integrated_db.empty:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨")
        return

    # í•™ìŠµ í…œí”Œë¦¿ ìƒì„±
    db_builder.save_training_templates()

    # ê²°ê³¼ ì¶œë ¥
    info = db_builder.get_database_info()
    print(f"\nâœ… í†µí•© ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ê³¼ëª© ìˆ˜: {info['total_subjects']}")
    print(f"ğŸ‘¨â€ğŸ« ì´ êµìˆ˜ ìˆ˜: {info['total_professors']}")
    print(f"ğŸ”¢ ê³ ìœ  ê³¼ëª© ì½”ë“œ: {info['unique_codes']}")
    print(f"ğŸ“… í¬í•¨ í•™ê¸°: {', '.join(info['semesters'])}")

    print(f"\nğŸ“ˆ ì£¼ìš” ê³¼ëª© (ìƒìœ„ 5ê°œ):")
    for subject, count in list(info['most_common_subjects'].items())[:5]:
        print(f"  â€¢ {subject}: {count}íšŒ")

    print(f"\nğŸ’¾ ìƒì„±ëœ íŒŒì¼:")
    print(f"  â€¢ data/integrated_subject_database.xlsx")
    print(f"  â€¢ data/templates/subject_aliases_template.xlsx")
    print(f"  â€¢ data/templates/professor_subject_mapping.xlsx")
    print(f"  â€¢ data/templates/database_statistics.xlsx")

    print("=" * 60)


if __name__ == "__main__":
    main()