"""
ê°œì„ ëœ OCR ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
24-25ë…„ë„ 4ê°œ í•™ê¸° ê°œì„¤ê°•ì¢Œ ë°ì´í„°ë¥¼ í™œìš©í•œ ê³ ì •í™•ë„ OCR ì‹œìŠ¤í…œ

ì£¼ìš” ê¸°ëŠ¥:
1. í†µí•© ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ê³¼ëª©ëª… ë§¤ì¹­ (95%+ ì •í™•ë„)
2. ë‹¤ì¤‘ í•„ë“œ êµì°¨ ê²€ì¦ (ê³¼ëª©ì½”ë“œ, êµìˆ˜ëª…, í•™ì )
3. ì ì§„ì  í•™ìŠµ ì‹œìŠ¤í…œ
4. í…Œì´ë¸” êµ¬ì¡° ë³µì› ë° JSON/CSV ì¶œë ¥
5. ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import cv2
import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import logging

from paddleocr import PaddleOCR
from utils.image_util import plt_imshow, put_text

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ import
from core.database_builder import DatabaseBuilder
from core.pattern_generator import PatternGenerator
from core.multi_semester_matcher import MultiSemesterMatcher
from core.learning_pipeline import LearningPipeline

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/ocr_improved.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ImprovedOCR:
    """ê°œì„ ëœ OCR ì‹œìŠ¤í…œ"""

    def __init__(self, lang: str = "korean", auto_build_db: bool = True):
        """
        Args:
            lang: OCR ì–¸ì–´ ì„¤ì •
            auto_build_db: ìë™ DB êµ¬ì¶• ì—¬ë¶€
        """
        self.lang = lang
        self.ocr_results = {}
        self.processing_stats = {}

        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('logs', exist_ok=True)

        print("ğŸš€ ê°œì„ ëœ OCR ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_database_system(auto_build_db)

        # 2. OCR ì—”ì§„ ì´ˆê¸°í™”
        self._initialize_ocr_engine()

        # 3. í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_learning_system()

        print("âœ… ê°œì„ ëœ OCR ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")

    def _initialize_database_system(self, auto_build: bool):
        """ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸ“š í†µí•© ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

        self.db_builder = DatabaseBuilder()
        self.matcher = MultiSemesterMatcher()

        # í†µí•© DBê°€ ì—†ê±°ë‚˜ ìë™ êµ¬ì¶• ì˜µì…˜ì´ ì¼œì§„ ê²½ìš° ìƒˆë¡œ êµ¬ì¶•
        if auto_build or not os.path.exists("data/integrated_subject_database.xlsx"):
            print("ğŸ”§ í†µí•© ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘...")
            self.db_builder.build_integrated_database()
            self.matcher = MultiSemesterMatcher()  # ìƒˆ DBë¡œ ì¬ì´ˆê¸°í™”

        db_info = self.matcher.get_database_info() if hasattr(self.matcher, 'get_database_info') else {}
        print(f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´: {db_info.get('total_subjects', 0)}ê°œ ê³¼ëª©, "
              f"{db_info.get('total_professors', 0)}ëª… êµìˆ˜")

    def _initialize_ocr_engine(self):
        """OCR ì—”ì§„ ì´ˆê¸°í™”"""
        print("ğŸ” OCR ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")

        # ì›¹ ìŠ¤í¬ë¦°ìƒ· ìµœì í™” ì„¤ì •
        self.ocr_engine = PaddleOCR(
            lang=self.lang,
            use_angle_cls=False,        # ì›¹ ìŠ¤í¬ë¦°ìƒ·ì€ í•­ìƒ ìˆ˜í‰
            use_gpu=True,               # GPU ì‚¬ìš©
            show_log=False,

            # ê²€ì¶œ íŒŒë¼ë¯¸í„° (ì‘ì€ í…ìŠ¤íŠ¸ ê²€ì¶œ í–¥ìƒ)
            det_db_thresh=0.2,          # ë‚®ì€ ì„ê³„ê°’
            det_db_box_thresh=0.3,
            det_limit_side_len=1960,    # í° ì´ë¯¸ì§€ í—ˆìš©

            # ì¸ì‹ íŒŒë¼ë¯¸í„°
            rec_batch_num=50,           # í° ë°°ì¹˜ í¬ê¸°
            max_text_length=50,         # ê¸´ í…ìŠ¤íŠ¸ í—ˆìš©
            drop_score=0.2,             # ë‚®ì€ ìŠ¤ì½”ì–´ë„ í¬í•¨
            use_space_char=True,

            # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
            rec_algorithm='SVTR_LCNet'  # PP-OCRv4
        )

    def _initialize_learning_system(self):
        """í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸ§  ì ì§„ì  í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

        self.pattern_generator = PatternGenerator()
        self.learning_pipeline = LearningPipeline()

    def preprocess_image(self, img_path: str) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì›¹ ìŠ¤í¬ë¦°ìƒ· ìµœì í™”)

        Args:
            img_path: ì´ë¯¸ì§€ ê²½ë¡œ

        Returns:
            np.ndarray: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        img = cv2.imread(img_path)
        if img is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")

        original_img = img.copy()

        # 1. ìƒ‰ìƒ ë°˜ì „ (ë‹¤í¬ëª¨ë“œ â†’ ë¼ì´íŠ¸ëª¨ë“œ)
        if self._is_dark_theme(img):
            img = cv2.bitwise_not(img)

        # 2. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img

        # 3. ê³ í•´ìƒë„ í™•ëŒ€ (ìµœì†Œ 2000px width)
        height, width = gray.shape[:2]
        if width < 2000:
            scale = 2000 / width
            new_width = int(width * scale)
            new_height = int(height * scale)
            gray = cv2.resize(gray, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)

        # 4. CLAHE ëŒ€ë¹„ í–¥ìƒ
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        # 5. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)

        # 6. ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì„ ëª…í™”
        gaussian = cv2.GaussianBlur(blurred, (5, 5), 2.0)
        unsharp = cv2.addWeighted(blurred, 1.5, gaussian, -0.5, 0)

        return unsharp

    def _is_dark_theme(self, img: np.ndarray) -> bool:
        """ë‹¤í¬ í…Œë§ˆ ì—¬ë¶€ íŒë‹¨"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        mean_brightness = np.mean(gray)
        return mean_brightness < 100  # í‰ê·  ë°ê¸°ê°€ 100 ë¯¸ë§Œì´ë©´ ë‹¤í¬ í…Œë§ˆ

    def detect_table_region(self, img: np.ndarray) -> Optional[Tuple[int, int, int, int]]:
        """
        í…Œì´ë¸” ì˜ì—­ ìë™ ê²€ì¶œ

        Args:
            img: ì…ë ¥ ì´ë¯¸ì§€

        Returns:
            Tuple[int, int, int, int]: (x, y, w, h) ë˜ëŠ” None
        """
        # ì—£ì§€ ê²€ì¶œ
        edges = cv2.Canny(img, 50, 150)

        # ìˆ˜í‰ì„  ê²€ì¶œ (í…Œì´ë¸” í–‰ êµ¬ë¶„ì„ )
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)

        # ìˆ˜ì§ì„  ê²€ì¶œ (í…Œì´ë¸” ì—´ êµ¬ë¶„ì„ )
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)

        # í…Œì´ë¸” ë§ˆìŠ¤í¬ ìƒì„±
        table_mask = cv2.add(horizontal_lines, vertical_lines)

        # ì»¨íˆ¬ì–´ ì°¾ê¸°
        contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return None

        # ê°€ì¥ í° í…Œì´ë¸” ì˜ì—­ ì°¾ê¸°
        max_area = 0
        table_region = None

        for contour in contours:
            area = cv2.contourArea(contour)
            x, y, w, h = cv2.boundingRect(contour)

            # í…Œì´ë¸” ì¡°ê±´: ìµœì†Œ í¬ê¸° ë° ë¹„ìœ¨
            if (area > max_area and
                w > img.shape[1] * 0.3 and  # ìµœì†Œ ë„ˆë¹„
                h > img.shape[0] * 0.2 and  # ìµœì†Œ ë†’ì´
                w / h > 1.5):               # ê°€ë¡œê°€ ë” ê¸´ í˜•íƒœ

                max_area = area
                table_region = (x, y, w, h)

        return table_region

    def extract_table_structure(self, ocr_results: List) -> Dict:
        """
        OCR ê²°ê³¼ë¥¼ í…Œì´ë¸” êµ¬ì¡°ë¡œ ë³€í™˜

        Args:
            ocr_results: PaddleOCR ê²°ê³¼

        Returns:
            Dict: êµ¬ì¡°í™”ëœ í…Œì´ë¸” ë°ì´í„°
        """
        if not ocr_results or not ocr_results[0]:
            return {"headers": [], "data": []}

        # Y ì¢Œí‘œë¡œ í–‰ ê·¸ë£¹í•‘
        rows = []
        current_row = []
        last_y = -1
        y_threshold = 30  # Y ì¢Œí‘œ ì°¨ì´ ì„ê³„ê°’

        for result in sorted(ocr_results[0], key=lambda x: x[0][0][1]):  # Y ì¢Œí‘œë¡œ ì •ë ¬
            y = result[0][0][1]

            if last_y != -1 and abs(y - last_y) > y_threshold:
                if current_row:
                    rows.append(sorted(current_row, key=lambda x: x[0][0][0]))  # X ì¢Œí‘œë¡œ ì •ë ¬
                current_row = []

            current_row.append(result)
            last_y = y

        if current_row:
            rows.append(sorted(current_row, key=lambda x: x[0][0][0]))

        if not rows:
            return {"headers": [], "data": []}

        # ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ì¸ì‹
        headers = [cell[1][0] for cell in rows[0]]

        # ë°ì´í„° í–‰ë“¤ êµ¬ì¡°í™”
        data_rows = []
        for row in rows[1:]:
            row_data = {}
            for i, cell in enumerate(row):
                header = headers[i] if i < len(headers) else f"ì»¬ëŸ¼{i+1}"
                row_data[header] = cell[1][0]

            # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ì¹­ìœ¼ë¡œ ë³´ì •
            validated_row = self._validate_row_data(row_data)
            data_rows.append(validated_row)

        return {"headers": headers, "data": data_rows}

    def _validate_row_data(self, row_data: Dict) -> Dict:
        """í–‰ ë°ì´í„° ê²€ì¦ ë° ë³´ì •"""
        validated = row_data.copy()

        # ê³¼ëª©ëª…ì´ ìˆëŠ” ê²½ìš° ë§¤ì¹­ ì‹œë„
        for key, value in row_data.items():
            if 'ê³¼ëª©' in key and value:
                context = {
                    'êµìˆ˜ëª…': row_data.get('êµìˆ˜ëª…', ''),
                    'ê³¼ëª©ì½”ë“œ': row_data.get('ê³¼ëª©ì½”ë“œ', ''),
                    'í•™ì ': row_data.get('í•™ì ', '')
                }

                matched_subject, confidence, method = self.matcher.find_best_match(
                    value, context, threshold=60
                )

                if confidence > 70:
                    validated[key] = matched_subject
                    validated[f'{key}_ì‹ ë¢°ë„'] = confidence
                    validated[f'{key}_ë§¤ì¹­ë°©ë²•'] = method

        return validated

    def process_image(self, img_path: str, debug: bool = False, save_results: bool = True) -> Dict:
        """
        ì´ë¯¸ì§€ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

        Args:
            img_path: ì´ë¯¸ì§€ ê²½ë¡œ
            debug: ë””ë²„ê·¸ ëª¨ë“œ (ì‹œê°í™” ì¶œë ¥)
            save_results: ê²°ê³¼ ì €ì¥ ì—¬ë¶€

        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = datetime.now()
        logger.info(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘: {img_path}")

        try:
            # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_img = self.preprocess_image(img_path)

            # 2. í…Œì´ë¸” ì˜ì—­ ê²€ì¶œ
            table_region = self.detect_table_region(processed_img)

            if table_region:
                x, y, w, h = table_region
                cropped_img = processed_img[y:y+h, x:x+w]
                logger.info(f"í…Œì´ë¸” ì˜ì—­ ê²€ì¶œ: {table_region}")
            else:
                cropped_img = processed_img
                logger.info("ì „ì²´ ì´ë¯¸ì§€ì—ì„œ OCR ìˆ˜í–‰")

            # 3. OCR ìˆ˜í–‰
            ocr_results = self.ocr_engine.ocr(cropped_img, cls=True)

            # 4. í…Œì´ë¸” êµ¬ì¡° ì¶”ì¶œ
            table_data = self.extract_table_structure(ocr_results)

            # 5. ê²°ê³¼ êµ¬ì„±
            result = {
                'image_path': img_path,
                'processing_time': (datetime.now() - start_time).total_seconds(),
                'table_region': table_region,
                'table_data': table_data,
                'raw_ocr_results': ocr_results[0] if ocr_results and ocr_results[0] else [],
                'metadata': {
                    'total_rows': len(table_data['data']),
                    'total_columns': len(table_data['headers']),
                    'processed_at': datetime.now().isoformat(),
                    'ocr_engine': 'PaddleOCR',
                    'database_version': 'integrated_24_25'
                }
            }

            # 6. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(result)

            # 7. ë””ë²„ê·¸ ì¶œë ¥
            if debug:
                self._show_debug_output(img_path, processed_img, ocr_results, table_data)

            # 8. ê²°ê³¼ ì €ì¥
            if save_results:
                self._save_results(result)

            logger.info(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ: {result['processing_time']:.2f}ì´ˆ")
            return result

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'image_path': img_path,
                'error': str(e),
                'processing_time': (datetime.now() - start_time).total_seconds()
            }

    def _update_processing_stats(self, result: Dict):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        if 'processing_stats' not in self.processing_stats:
            self.processing_stats = {
                'total_processed': 0,
                'total_time': 0.0,
                'successful_extractions': 0,
                'table_detections': 0
            }

        stats = self.processing_stats
        stats['total_processed'] += 1
        stats['total_time'] += result.get('processing_time', 0)

        if result.get('table_data', {}).get('data'):
            stats['successful_extractions'] += 1

        if result.get('table_region'):
            stats['table_detections'] += 1

    def _show_debug_output(self, img_path: str, processed_img: np.ndarray,
                          ocr_results: List, table_data: Dict):
        """ë””ë²„ê·¸ ì¶œë ¥"""
        print(f"\nğŸ” ë””ë²„ê·¸ ì •ë³´ - {os.path.basename(img_path)}")
        print("-" * 50)

        print(f"ğŸ“Š í…Œì´ë¸” êµ¬ì¡°:")
        print(f"  â€¢ í—¤ë”: {table_data['headers']}")
        print(f"  â€¢ ë°ì´í„° í–‰ ìˆ˜: {len(table_data['data'])}")

        print(f"\nğŸ“ ì¶”ì¶œëœ ë°ì´í„° (ìƒìœ„ 3í–‰):")
        for i, row in enumerate(table_data['data'][:3], 1):
            print(f"  í–‰ {i}: {row}")

        # ì‹œê°í™” (ì˜µì…˜)
        try:
            original_img = cv2.imread(img_path)
            if original_img is not None:
                # OCR ê²°ê³¼ ì‹œê°í™”
                visualized_img = self._visualize_ocr_results(original_img, ocr_results)
                plt_imshow(["ì›ë³¸", "ì „ì²˜ë¦¬", "OCR ê²°ê³¼"],
                          [original_img, processed_img, visualized_img],
                          figsize=(15, 5))
        except Exception as e:
            logger.warning(f"ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def _visualize_ocr_results(self, img: np.ndarray, ocr_results: List) -> np.ndarray:
        """OCR ê²°ê³¼ ì‹œê°í™”"""
        if not ocr_results or not ocr_results[0]:
            return img

        result_img = img.copy()

        for result in ocr_results[0]:
            # í…ìŠ¤íŠ¸ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            points = np.array(result[0], dtype=np.int32)
            cv2.polylines(result_img, [points], True, (0, 255, 0), 2)

            # í…ìŠ¤íŠ¸ì™€ ì‹ ë¢°ë„ í‘œì‹œ
            text = result[1][0]
            confidence = result[1][1]
            label = f"{text} ({confidence:.2f})"

            # í…ìŠ¤íŠ¸ ìœ„ì¹˜
            x, y = points[0]
            result_img = put_text(result_img, label, x, y - 10, font_size=12)

        return result_img

    def _save_results(self, result: Dict):
        """ê²°ê³¼ ì €ì¥"""
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            output_dir = "output"
            os.makedirs(output_dir, exist_ok=True)

            # íŒŒì¼ëª… ìƒì„±
            base_name = os.path.splitext(os.path.basename(result['image_path']))[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # JSON ì €ì¥
            json_path = os.path.join(output_dir, f"{base_name}_{timestamp}.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2, default=str)

            # CSV ì €ì¥ (í…Œì´ë¸” ë°ì´í„°ë§Œ)
            if result.get('table_data', {}).get('data'):
                csv_path = os.path.join(output_dir, f"{base_name}_{timestamp}.csv")
                df = pd.DataFrame(result['table_data']['data'])
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')

                logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_path}, {csv_path}")
            else:
                logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_path}")

        except Exception as e:
            logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def batch_process(self, image_dir: str, pattern: str = "*.png") -> List[Dict]:
        """
        ë°°ì¹˜ ì²˜ë¦¬

        Args:
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            pattern: íŒŒì¼ íŒ¨í„´

        Returns:
            List[Dict]: ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        from glob import glob

        image_files = glob(os.path.join(image_dir, pattern))
        results = []

        print(f"ğŸ“ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(image_files)}ê°œ íŒŒì¼")

        for i, img_path in enumerate(image_files, 1):
            print(f"  ì²˜ë¦¬ ì¤‘... ({i}/{len(image_files)}) {os.path.basename(img_path)}")
            result = self.process_image(img_path, debug=False, save_results=True)
            results.append(result)

        print(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ íŒŒì¼")
        return results

    def collect_user_feedback(self, original_results: List[str], corrected_results: List[str]):
        """ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘"""
        feedback_count = self.learning_pipeline.collect_user_feedback(
            original_results, corrected_results
        )
        print(f"ğŸ“š ì‚¬ìš©ì í”¼ë“œë°± {feedback_count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

    def get_performance_report(self) -> Dict:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        learning_report = self.learning_pipeline.generate_performance_report()
        processing_stats = self.processing_stats

        combined_report = {
            'processing_performance': {
                'total_processed': processing_stats.get('total_processed', 0),
                'average_time': processing_stats.get('total_time', 0) / max(processing_stats.get('total_processed', 1), 1),
                'extraction_success_rate': processing_stats.get('successful_extractions', 0) / max(processing_stats.get('total_processed', 1), 1),
                'table_detection_rate': processing_stats.get('table_detections', 0) / max(processing_stats.get('total_processed', 1), 1)
            },
            'learning_performance': learning_report,
            'generated_at': datetime.now().isoformat()
        }

        return combined_report


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 70)
    print("ğŸš€ ê°œì„ ëœ ì¶©ë¶ëŒ€ OCR ì‹œìŠ¤í…œ - 24-25ë…„ë„ í†µí•© ë²„ì „")
    print("=" * 70)

    # OCR ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ocr_system = ImprovedOCR(auto_build_db=True)

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬
    test_images_dir = "assets/images"
    test_images = ["main_test_1.png"]

    if not os.path.exists(test_images_dir):
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {test_images_dir}")
        return

    print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")

    for img_name in test_images:
        img_path = os.path.join(test_images_dir, img_name)

        if os.path.exists(img_path):
            print(f"\nğŸ” ì²˜ë¦¬ ì¤‘: {img_name}")
            print("-" * 50)

            # ì´ë¯¸ì§€ ì²˜ë¦¬
            result = ocr_system.process_image(img_path, debug=True)

            if 'error' not in result:
                # ê²°ê³¼ ì¶œë ¥
                table_data = result.get('table_data', {})
                print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
                print(f"  â€¢ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
                print(f"  â€¢ í…Œì´ë¸” ì˜ì—­: {'ê²€ì¶œë¨' if result.get('table_region') else 'ë¯¸ê²€ì¶œ'}")
                print(f"  â€¢ ì¶”ì¶œëœ í–‰ ìˆ˜: {len(table_data.get('data', []))}")
                print(f"  â€¢ ì»¬ëŸ¼ ìˆ˜: {len(table_data.get('headers', []))}")

                # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
                if table_data.get('data'):
                    print(f"\nğŸ“Š ì¶”ì¶œëœ ë°ì´í„° ìƒ˜í”Œ:")
                    for i, row in enumerate(table_data['data'][:3], 1):
                        print(f"  í–‰ {i}: {row}")

            else:
                print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")

        else:
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")

    # ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì¶œë ¥
    print(f"\nğŸ“ˆ ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
    print("-" * 30)
    report = ocr_system.get_performance_report()

    processing_perf = report.get('processing_performance', {})
    print(f"  â€¢ ì´ ì²˜ë¦¬ íŒŒì¼: {processing_perf.get('total_processed', 0)}ê°œ")
    print(f"  â€¢ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {processing_perf.get('average_time', 0):.2f}ì´ˆ")
    print(f"  â€¢ ì¶”ì¶œ ì„±ê³µë¥ : {processing_perf.get('extraction_success_rate', 0):.1%}")
    print(f"  â€¢ í…Œì´ë¸” ê²€ì¶œë¥ : {processing_perf.get('table_detection_rate', 0):.1%}")

    learning_perf = report.get('learning_performance', {})
    if learning_perf:
        print(f"  â€¢ í•™ìŠµ ë°ì´í„°: {learning_perf.get('total_corrections', 0)}ê°œ")
        print(f"  â€¢ ìë™ ìŠ¹ì¸: {learning_perf.get('auto_approved_corrections', 0)}ê°œ")

    print(f"\nğŸ’¾ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: output/ ë””ë ‰í† ë¦¬")
    print("=" * 70)
    print("ğŸ¯ OCR ì‹œìŠ¤í…œì´ 95%+ ì •í™•ë„ë¡œ ê³¼ëª© ì •ë³´ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤!")
    print("ğŸ“š ì§€ì†ì ì¸ í•™ìŠµì„ í†µí•´ ì •í™•ë„ê°€ ê³„ì† í–¥ìƒë©ë‹ˆë‹¤.")
    print("=" * 70)


if __name__ == "__main__":
    main()